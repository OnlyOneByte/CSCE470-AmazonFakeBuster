{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.4 64-bit ('base': conda)",
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "73e03da126b73bfff3642ec5261d56fa25c444ea595de51041687efaa60dda41"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\Angelo\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\Angelo\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "\n",
    "\n",
    "# Stop words, lemmatization, punctiation\n",
    "# lemmatization = stronger stemming.\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             LABEL  RATING VERIFIED_PURCHASE PRODUCT_CATEGORY  PRODUCT_ID  \\\n",
       "DOC_ID                                                                      \n",
       "1       __label1__       4                 N               PC  B00008NG7N   \n",
       "2       __label1__       4                 Y         Wireless  B00LH0Y3NM   \n",
       "3       __label1__       3                 N             Baby  B000I5UZ1Q   \n",
       "4       __label1__       4                 N  Office Products  B003822IRA   \n",
       "5       __label1__       4                 N           Beauty  B00PWSAXAM   \n",
       "\n",
       "                                            PRODUCT_TITLE  \\\n",
       "DOC_ID                                                      \n",
       "1             Targus PAUK10U Ultra Mini USB Keypad, Black   \n",
       "2       Note 3 Battery : Stalion Strength Replacement ...   \n",
       "3            Fisher-Price Papasan Cradle Swing, Starlight   \n",
       "4       Casio MS-80B Standard Function Desktop Calculator   \n",
       "5       Shine Whitening - Zero Peroxide Teeth Whitenin...   \n",
       "\n",
       "                    REVIEW_TITLE  \\\n",
       "DOC_ID                             \n",
       "1                         useful   \n",
       "2          New era for batteries   \n",
       "3       doesn't swing very well.   \n",
       "4               Great computing!   \n",
       "5          Only use twice a week   \n",
       "\n",
       "                                              REVIEW_TEXT  \n",
       "DOC_ID                                                     \n",
       "1       When least you think so, this product will sav...  \n",
       "2       Lithium batteries are something new introduced...  \n",
       "3       I purchased this swing for my baby. She is 6 m...  \n",
       "4       I was looking for an inexpensive desk calcolat...  \n",
       "5       I only use it twice a week and the results are...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LABEL</th>\n      <th>RATING</th>\n      <th>VERIFIED_PURCHASE</th>\n      <th>PRODUCT_CATEGORY</th>\n      <th>PRODUCT_ID</th>\n      <th>PRODUCT_TITLE</th>\n      <th>REVIEW_TITLE</th>\n      <th>REVIEW_TEXT</th>\n    </tr>\n    <tr>\n      <th>DOC_ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>__label1__</td>\n      <td>4</td>\n      <td>N</td>\n      <td>PC</td>\n      <td>B00008NG7N</td>\n      <td>Targus PAUK10U Ultra Mini USB Keypad, Black</td>\n      <td>useful</td>\n      <td>When least you think so, this product will sav...</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>__label1__</td>\n      <td>4</td>\n      <td>Y</td>\n      <td>Wireless</td>\n      <td>B00LH0Y3NM</td>\n      <td>Note 3 Battery : Stalion Strength Replacement ...</td>\n      <td>New era for batteries</td>\n      <td>Lithium batteries are something new introduced...</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>__label1__</td>\n      <td>3</td>\n      <td>N</td>\n      <td>Baby</td>\n      <td>B000I5UZ1Q</td>\n      <td>Fisher-Price Papasan Cradle Swing, Starlight</td>\n      <td>doesn't swing very well.</td>\n      <td>I purchased this swing for my baby. She is 6 m...</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>__label1__</td>\n      <td>4</td>\n      <td>N</td>\n      <td>Office Products</td>\n      <td>B003822IRA</td>\n      <td>Casio MS-80B Standard Function Desktop Calculator</td>\n      <td>Great computing!</td>\n      <td>I was looking for an inexpensive desk calcolat...</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>__label1__</td>\n      <td>4</td>\n      <td>N</td>\n      <td>Beauty</td>\n      <td>B00PWSAXAM</td>\n      <td>Shine Whitening - Zero Peroxide Teeth Whitenin...</td>\n      <td>Only use twice a week</td>\n      <td>I only use it twice a week and the results are...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "corpus_df = pd.read_csv(\"corpus.tsv\", sep=\"\\t\")\n",
    "corpus_df = corpus_df.set_index(\"DOC_ID\")\n",
    "corpus_df.head()"
   ]
  },
  {
   "source": [
    "## Parse through data and clean things up"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             LABEL  RATING VERIFIED_PURCHASE PRODUCT_CATEGORY  PRODUCT_ID  \\\n",
       "DOC_ID                                                                      \n",
       "1       __label1__       4                 N               PC  B00008NG7N   \n",
       "2       __label1__       4                 Y         Wireless  B00LH0Y3NM   \n",
       "3       __label1__       3                 N             Baby  B000I5UZ1Q   \n",
       "4       __label1__       4                 N  Office Products  B003822IRA   \n",
       "5       __label1__       4                 N           Beauty  B00PWSAXAM   \n",
       "\n",
       "                                            PRODUCT_TITLE  \\\n",
       "DOC_ID                                                      \n",
       "1             Targus PAUK10U Ultra Mini USB Keypad, Black   \n",
       "2       Note 3 Battery : Stalion Strength Replacement ...   \n",
       "3            Fisher-Price Papasan Cradle Swing, Starlight   \n",
       "4       Casio MS-80B Standard Function Desktop Calculator   \n",
       "5       Shine Whitening - Zero Peroxide Teeth Whitenin...   \n",
       "\n",
       "                    REVIEW_TITLE  \\\n",
       "DOC_ID                             \n",
       "1                         useful   \n",
       "2          New era for batteries   \n",
       "3       doesn't swing very well.   \n",
       "4               Great computing!   \n",
       "5          Only use twice a week   \n",
       "\n",
       "                                              REVIEW_TEXT  \\\n",
       "DOC_ID                                                      \n",
       "1       When least you think so, this product will sav...   \n",
       "2       Lithium batteries are something new introduced...   \n",
       "3       I purchased this swing for my baby. She is 6 m...   \n",
       "4       I was looking for an inexpensive desk calcolat...   \n",
       "5       I only use it twice a week and the results are...   \n",
       "\n",
       "                                       PARSED_REVIEW_TEXT  \n",
       "DOC_ID                                                     \n",
       "1       [when least, least think, think product, produ...  \n",
       "2       [lithium battery, battery something, something...  \n",
       "3       [i purchased, purchased swing, swing baby, bab...  \n",
       "4       [i looking, looking inexpensive, inexpensive d...  \n",
       "5       [i use, use twice, twice week, week result, re...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LABEL</th>\n      <th>RATING</th>\n      <th>VERIFIED_PURCHASE</th>\n      <th>PRODUCT_CATEGORY</th>\n      <th>PRODUCT_ID</th>\n      <th>PRODUCT_TITLE</th>\n      <th>REVIEW_TITLE</th>\n      <th>REVIEW_TEXT</th>\n      <th>PARSED_REVIEW_TEXT</th>\n    </tr>\n    <tr>\n      <th>DOC_ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>__label1__</td>\n      <td>4</td>\n      <td>N</td>\n      <td>PC</td>\n      <td>B00008NG7N</td>\n      <td>Targus PAUK10U Ultra Mini USB Keypad, Black</td>\n      <td>useful</td>\n      <td>When least you think so, this product will sav...</td>\n      <td>[when least, least think, think product, produ...</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>__label1__</td>\n      <td>4</td>\n      <td>Y</td>\n      <td>Wireless</td>\n      <td>B00LH0Y3NM</td>\n      <td>Note 3 Battery : Stalion Strength Replacement ...</td>\n      <td>New era for batteries</td>\n      <td>Lithium batteries are something new introduced...</td>\n      <td>[lithium battery, battery something, something...</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>__label1__</td>\n      <td>3</td>\n      <td>N</td>\n      <td>Baby</td>\n      <td>B000I5UZ1Q</td>\n      <td>Fisher-Price Papasan Cradle Swing, Starlight</td>\n      <td>doesn't swing very well.</td>\n      <td>I purchased this swing for my baby. She is 6 m...</td>\n      <td>[i purchased, purchased swing, swing baby, bab...</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>__label1__</td>\n      <td>4</td>\n      <td>N</td>\n      <td>Office Products</td>\n      <td>B003822IRA</td>\n      <td>Casio MS-80B Standard Function Desktop Calculator</td>\n      <td>Great computing!</td>\n      <td>I was looking for an inexpensive desk calcolat...</td>\n      <td>[i looking, looking inexpensive, inexpensive d...</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>__label1__</td>\n      <td>4</td>\n      <td>N</td>\n      <td>Beauty</td>\n      <td>B00PWSAXAM</td>\n      <td>Shine Whitening - Zero Peroxide Teeth Whitenin...</td>\n      <td>Only use twice a week</td>\n      <td>I only use it twice a week and the results are...</td>\n      <td>[i use, use twice, twice week, week result, re...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# parses review text\n",
    "# tokenizes, lemmatizes, filters stop words, creates bigrams\n",
    "table = str.maketrans({key: None for key in string.punctuation})\n",
    "def parseReviewText(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = text.translate(table)\n",
    "    filtered_tokens=[]\n",
    "    lemmatized_tokens = []\n",
    "    for w in text.split(\" \"):\n",
    "        if w not in stop_words:\n",
    "            lemmatized_tokens.append(lemmatizer.lemmatize(w.lower()))\n",
    "        filtered_tokens = [' '.join(l) for l in nltk.bigrams(lemmatized_tokens)] + lemmatized_tokens\n",
    "    return filtered_tokens\n",
    "corpus_df[\"PARSED_REVIEW_TEXT\"] = corpus_df[\"REVIEW_TEXT\"].apply(parseReviewText)\n",
    "\n",
    "\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df.to_pickle(\"pickles/pickled_parsed_df.pkl\")"
   ]
  },
  {
   "source": [
    "## Generate feature vectors of each review"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = corpus_df[[\"LABEL\", \"RATING\", \"PRODUCT_CATEGORY\", \"VERIFIED_PURCHASE\", \"PARSED_REVIEW_TEXT\"]].values\n",
    "featureDict = {} # A global dictionary of features\n",
    "\n",
    "# taking into account diff values\n",
    "data_X = []\n",
    "data_y = []\n",
    "for x in data:\n",
    "    # some global stuff for debugging and info\n",
    "    if x[2] not in featureDict:\n",
    "        featureDict[x[2]] = 1\n",
    "    else:\n",
    "        featureDict[x[2]] = +1\n",
    "    featureDict[\"VP\"] = 1\n",
    "    featureDict[\"R\"] = 1  \n",
    "\n",
    "\n",
    "    localDict = {}\n",
    "\n",
    "    # x is: label, rating, category, verified, [parsed text tokens]\n",
    "    localDict[\"R\"] = x[1]\n",
    "\n",
    "    #Verified_Purchase\n",
    "    if x[3] == \"N\":\n",
    "        localDict[\"VP\"] = 0\n",
    "    else:\n",
    "        localDict[\"VP\"] = 1\n",
    "        \n",
    "    #Product_Category\n",
    "    if x[2] not in localDict:\n",
    "        localDict[x[2]] = 1\n",
    "    else:\n",
    "        localDict[x[2]] = +1\n",
    "            \n",
    "    #Text        \n",
    "    for token in x[4]:\n",
    "        if token not in featureDict:\n",
    "            featureDict[token] = 1\n",
    "        else:\n",
    "            featureDict[token] = +1\n",
    "            \n",
    "        if token not in localDict:\n",
    "            localDict[token] = 1\n",
    "        else:\n",
    "            localDict[token] = +1\n",
    "\n",
    "    label = \"FAKE\" if x[0] == \"__label1__\" else \"REAL\"\n",
    "    \n",
    "    data_X.append(localDict)\n",
    "    data_y.append(label)  "
   ]
  },
  {
   "source": [
    "## For testing only, split into train and test sets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of data points\nTrain: 16800 Test: 4200\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.2, random_state=42)\n",
    "print(\"Number of data points\")\n",
    "print(\"Train:\", len(X_train), \"Test:\", len(X_test))"
   ]
  },
  {
   "source": [
    "## Generate the classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "training_set = [(X_train[x], y_train[x]) for x in range(len(X_train))]\n",
    "\n",
    "pipeline =  Pipeline([('svc', LinearSVC(C=0.01))])\n",
    "clf = SklearnClassifier(pipeline).train(training_set)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Test Classifier on testing set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy:  0.810952380952381\nPrecision:  0.8125154427084342\nRecall:  0.810952380952381\nf1-score:  0.8107927346407253\n"
     ]
    }
   ],
   "source": [
    "test_set = [(X_test[x], y_test[x]) for x in range(len(X_test))]\n",
    "\n",
    "predictions = clf.classify_many(map(lambda t: t[0], test_set))\n",
    "true_labels = list(map(lambda d: d[1], test_set))\n",
    "a = accuracy_score(true_labels, predictions)\n",
    "p, r, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='macro')\n",
    "print(\"accuracy: \", a)\n",
    "print(\"Precision: \", p)\n",
    "print(\"Recall: \", a)\n",
    "print(\"f1-score: \", f1)"
   ]
  },
  {
   "source": [
    "## Generate classifier on full set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set = (data_X, data_y)\n",
    "pipeline =  Pipeline([('svc', LinearSVC(C=0.01))])\n",
    "clf = SklearnClassifier(pipeline).train(training_set)"
   ]
  },
  {
   "source": [
    "## Pickle/save classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open(\"pickles/full_dataset_classifier.pkl\", \"wb\"))"
   ]
  }
 ]
}